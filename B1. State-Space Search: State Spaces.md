# B1. State-Space Search: State Spaces

---

## B1.1 State-Space Search Problems

### Overview of State-Space Search
State-space search is a fundamental problem-solving approach in artificial intelligence (AI). It involves exploring a set of states and transitions to determine a sequence of actions that lead from an **initial state** to a **goal state**. This method is widely used in AI to solve problems where the solution can be represented as a path through a series of states.

### Applications of State-Space Search
State-space search is applied in various domains, including:

1. **Pathfinding**: 
   - Used in robotics, navigation systems, and game AI (e.g., Mario AI competition, multi-agent pathfinding).
   - Example: Finding the shortest path for a robot to navigate from point A to point B while avoiding obstacles.

2. **Scheduling**:
   - Applied in logistics, manufacturing, and software verification.
   - Example: Optimizing the schedule of tasks in a factory to minimize production time.

3. **NPC Behavior**:
   - Used in video games to control non-player characters (NPCs).
   - Example: Designing AI for NPCs to make decisions based on the game state.

### Classical Assumptions
To simplify the problem, classical state-space search makes the following assumptions:

1. **Single-agent environment**: The problem involves only one agent, and no other agents influence the search.
2. **Fully observable environment**: The agent has complete knowledge of the world state at all times.
3. **Static environment**: The environment remains unchanged unless the agent performs an action.
4. **Finite and discrete state space**: The problem consists of a finite number of states and actions.
5. **Deterministic transitions**: The outcome of each action is predictable and leads to a unique successor state.

These assumptions can be relaxed in more complex scenarios, but this discussion focuses on the classical case.

### Problem Definition
A **state-space search problem** is formally defined by the following components:

1. **Initial State**: The starting point of the search.
2. **Goal State**: The desired state or set of conditions that define the solution.
3. **Actions**: A set of possible actions that can be applied in different states.
4. **Transition Function**: A function that defines how actions modify states. It maps a state-action pair to a new state.
5. **Cost Function**: A function that assigns a numerical cost to each action. The goal is often to minimize the total cost of the path.

The objective is to find an **optimal path** from the initial state to a goal state that minimizes the total action cost.

### Example: The 15-Puzzle
A classic example of a state-space search problem is the **15-puzzle**. The puzzle consists of a 4x4 grid with 15 tiles and one empty space. The goal is to rearrange the tiles into a specific order by sliding them into the empty space.

- **States**: Each possible configuration of the tiles represents a state.
- **Actions**: Sliding a tile into the empty space.
- **Goal State**: The configuration where the tiles are in the correct order.

---

## B1.2 Formalization

### Definition of State Spaces
A **state space** (also called a transition system) is formally defined as a **6-tuple**:
\[ S = \langle S, A, \text{cost}, T, s_I, S_G \rangle \]
where:
- **\(S\)**: A finite set of possible states.
- **\(A\)**: A finite set of possible actions.
- **\(\text{cost}: A \to \mathbb{R}_{\geq 0}\)**: A function that assigns a non-negative cost to each action.
- **\(T \subseteq S \times A \times S\)**: A transition relation where each state-action pair leads to a unique successor state.
- **\(s_I \in S\)**: The initial state.
- **\(S_G \subseteq S\)**: The set of goal states.

### State-Space Transitions
- A **transition** \( (s, a, s') \in T \) represents moving from state \(s\) to state \(s'\) using action \(a\).
- Transitions are **deterministic**, meaning that a given action in a given state always leads to a unique successor state.

### Example: Bounded Inc-and-Square Search
Consider a number modification problem where actions **increment modulo 10** and **square modulo 10**:

- **States**: \( S = \{0, 1, ..., 9\} \)
- **Actions**: \( A = \{ \text{inc}, \text{sqr} \} \)
- **Transition Function**:
  - \( \langle i, \text{inc}, (i+1) \mod 10 \rangle \in T \)
  - \( \langle i, \text{sqr}, i^2 \mod 10 \rangle \in T \)
- **Initial State**: \( s_I = 1 \)
- **Goal States**: \( S_G = \{6, 7\} \)
- **Cost**: Each action costs 1.

### Graph Representation of State Spaces
State spaces can be represented as directed graphs:

- **Nodes**: Represent states.
- **Edges**: Represent transitions labeled by actions.
- **Initial State**: Marked with an incoming arrow.
- **Goal States**: Represented as double circles.

### Paths and Solutions
- A **path** from state \(s_0\) to state \(s_n\) is a sequence of actions that transforms \(s_0\) into \(s_n\).
- A **solution** is a path that leads to a goal state.
- An **optimal solution** has the minimal cost among all solutions.

---

## B1.3 State-Space Search

### Definition
**State-space search** is the problem of systematically exploring a state space to find a solution path or to prove that no solution exists.

### Solving Search Problems
To solve a state-space search problem, one must determine:

1. A **sequence of actions** that transforms the initial state into a goal state.
2. The **optimal sequence** (if optimizing for cost).

### Learning Objectives for State-Space Search
By studying state-space search, one should be able to:

1. **Define and formalize search problems**: Understand the components of a state-space search problem and how to represent them formally.
2. **Evaluate search algorithms**: Analyze algorithms in terms of **completeness, optimality, time complexity, and space complexity**.
3. **Differentiate between uninformed and informed search algorithms**: Understand the differences between algorithms that do not use problem-specific knowledge (e.g., breadth-first search) and those that do (e.g., A* search).
4. **Analyze and design heuristics**: Develop and evaluate heuristics that guide the search process efficiently.
5. **Implement and experimentally evaluate search algorithms**: Gain practical experience by implementing search algorithms and testing their performance.

---

## B1.4 Summary

### Key Takeaways
1. **State-space search problems** involve finding an optimal action sequence to reach a goal state.
2. **State-space formalization** includes defining states, actions, transitions, and costs.
3. **Graph representation** helps visualize state transitions and search paths.
4. **State-space search algorithms** explore and evaluate paths to efficiently find solutions.

State-space search is a foundational concept in AI, essential for pathfinding, planning, and problem-solving in various domains. By understanding the formalization and applications of state-space search, one can develop efficient algorithms to solve complex problems.

---

### Additional Concepts to Consider
- **Heuristics**: Functions that estimate the cost to reach the goal from a given state. They are crucial for informed search algorithms like A*.
- **Admissibility and Consistency**: Properties of heuristics that ensure optimality in search algorithms.
- **Search Strategies**: Different strategies like depth-first search, breadth-first search, and iterative deepening.
- **Complexity Analysis**: Understanding the time and space complexity of search algorithms in terms of the branching factor and depth of the search tree.

By incorporating these concepts, the notes provide a more comprehensive understanding of state-space search and its applications in AI.
